{"cells":[{"cell_type":"code","execution_count":3,"id":"bb1115eb-e872-4cf7-87d9-da4adf9c2d21","metadata":{"id":"bb1115eb-e872-4cf7-87d9-da4adf9c2d21"},"outputs":[],"source":["import tensorflow as tf\n","from tensorflow.keras import layers, models\n","from tensorflow.keras.datasets import mnist\n","import numpy as np\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n"]},{"cell_type":"markdown","id":"7f44ba4e","metadata":{"id":"7f44ba4e"},"source":["## Dataset MNIST\n","\n","El dataset **MNIST** consiste en imágenes de números manuscritos entre 0 y 9. Las imágenes tienen dimensiones de 28x28 pixeles y cada pixel está representado por un valor de intensidad en escala de grises. El conjunto de entrenamiento consiste en 60000 dígitos y el conjunto de prueba de 10000.\n","\n","### Implemente una CNN para obtener un desempeño de al menos 99% en el conjunto de prueba"]},{"cell_type":"code","execution_count":4,"id":"5b23ca64-c79a-42f6-83ab-ae720e92426b","metadata":{"id":"5b23ca64-c79a-42f6-83ab-ae720e92426b"},"outputs":[{"name":"stdout","output_type":"stream","text":["Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n","11490434/11490434 [==============================] - 1s 0us/step\n"]},{"data":{"text/plain":["' las variables train contienen las imagenes y las etiquetas para entrenar}\\ny las variables test contienen las de prueba'"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\" cargo el conjunto de datos MNIST\"\"\"\n","(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n","\n","\"\"\" las variables train contienen las imagenes y las etiquetas para entrenar}\n","y las variables test contienen las de prueba\"\"\""]},{"cell_type":"code","execution_count":5,"id":"9a512731","metadata":{},"outputs":[{"data":{"text/plain":["'las imagenes se remoldean para que tengan una forma adecuada para el cnn\\nademás se normalizan los valores de los pixeles de las imagenes para que esten en el rango [0,1]'"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["#Procesamiento de datos\n","train_images = train_images.reshape((60000, 28, 28, 1)) \n","test_images = test_images.reshape((10000, 28, 28, 1))\n","train_images, test_images = train_images / 255.0, test_images / 255.0\n","\"\"\"las imagenes se remoldean para que tengan una forma adecuada para el cnn\n","además se normalizan los valores de los pixeles de las imagenes para que esten en el rango [0,1]\"\"\""]},{"cell_type":"code","execution_count":7,"id":"7f15edee","metadata":{},"outputs":[{"data":{"text/plain":["'Se define la arquitectura de la CNN. Consta de 3 capas de convolución, seguidas de capas de maxpooling\\npara reducir el tamaño de las caracteriscas, flatten para aplanar los datos en un vector y dos capas densas para la clasificacion final\\nla funcion de activacion relu se usa para que la red pueda aprender funciones no lineales\\nla funcion de activacion softmax se usa para que la red pueda clasificar las imagenes en 10 clases'"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["#Definicion CNN\n","model = models.Sequential([\n","    layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)), #capa convolucional\n","    layers.MaxPooling2D((2, 2)), #capa de pooling\n","    layers.Conv2D(64, (3, 3), activation='relu'), #capa convolucional\n","    layers.MaxPooling2D((2, 2)), #capa de pooling\n","    layers.Conv2D(64, (3, 3), activation='relu'), #capa convolucional\n","    layers.Flatten(), #capa de aplanamiento\n","    layers.Dense(64, activation='relu'), #capa densa\n","    layers.Dense(10, activation='softmax') #capa de salida\n","])\n","\"\"\"Se define la arquitectura de la CNN. Consta de 3 capas de convolución, seguidas de capas de maxpooling\n","para reducir el tamaño de las caracteriscas, flatten para aplanar los datos en un vector y dos capas densas para la clasificacion final\n","la funcion de activacion relu se usa para que la red pueda aprender funciones no lineales\n","la funcion de activacion softmax se usa para que la red pueda clasificar las imagenes en 10 clases\"\"\""]},{"cell_type":"code","execution_count":9,"id":"c89bb4c5","metadata":{},"outputs":[],"source":["#Compilacion\n","model.compile(optimizer='adam',\n","              loss='sparse_categorical_crossentropy',\n","              metrics=['accuracy'])\n"," "]},{"cell_type":"code","execution_count":10,"id":"bc36edb0","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Epoch 1/15\n","938/938 [==============================] - 43s 44ms/step - loss: 0.1810 - accuracy: 0.9454\n","Epoch 2/15\n","938/938 [==============================] - 43s 46ms/step - loss: 0.0501 - accuracy: 0.9848\n","Epoch 3/15\n","938/938 [==============================] - 44s 47ms/step - loss: 0.0357 - accuracy: 0.9891\n","Epoch 4/15\n","938/938 [==============================] - 40s 42ms/step - loss: 0.0279 - accuracy: 0.9909\n","Epoch 5/15\n","938/938 [==============================] - 38s 41ms/step - loss: 0.0217 - accuracy: 0.9931\n","Epoch 6/15\n","938/938 [==============================] - 39s 42ms/step - loss: 0.0188 - accuracy: 0.9940\n","Epoch 7/15\n","938/938 [==============================] - 42s 45ms/step - loss: 0.0148 - accuracy: 0.9953\n","Epoch 8/15\n","938/938 [==============================] - 42s 45ms/step - loss: 0.0137 - accuracy: 0.9956\n","Epoch 9/15\n","938/938 [==============================] - 44s 47ms/step - loss: 0.0112 - accuracy: 0.9960\n","Epoch 10/15\n","938/938 [==============================] - 46s 49ms/step - loss: 0.0093 - accuracy: 0.9968\n","Epoch 11/15\n","938/938 [==============================] - 56s 59ms/step - loss: 0.0082 - accuracy: 0.9973\n","Epoch 12/15\n","938/938 [==============================] - 53s 57ms/step - loss: 0.0080 - accuracy: 0.9971\n","Epoch 13/15\n","938/938 [==============================] - 46s 49ms/step - loss: 0.0063 - accuracy: 0.9979\n","Epoch 14/15\n","938/938 [==============================] - 43s 46ms/step - loss: 0.0057 - accuracy: 0.9982\n","Epoch 15/15\n","938/938 [==============================] - 42s 45ms/step - loss: 0.0060 - accuracy: 0.9980\n"]},{"data":{"text/plain":["<keras.src.callbacks.History at 0x1d0d8704850>"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["#Entrenamiento\n","model.fit(train_images, train_labels, epochs=15, batch_size=64)\n","\"\"\"El modelo se entran usando los datos de entrenamiento\n","durante 15 épocas con un tamaño de lote de 64\"\"\""]},{"cell_type":"code","execution_count":11,"id":"fa1b2a7f","metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["313/313 [==============================] - 3s 9ms/step - loss: 0.0291 - accuracy: 0.9911\n","accuracy: 0.991100013256073\n"]},{"data":{"text/plain":["'En resumen en este codigo se carga el conjunto MNIST, crea un CNN,\\ncompila, entrenar y evalua el modelo. Por ultimo se imprime la precision del modelo\\n'"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["#Evaluacion\n","test_loss, test_acc = model.evaluate(test_images, test_labels)\n","print(f'accuracy: {test_acc}')\n","\"\"\"En resumen en este codigo se carga el conjunto MNIST, crea un CNN,\n","compila, entrenar y evalua el modelo. Por ultimo se imprime la precision del modelo\n","\"\"\""]},{"cell_type":"code","execution_count":null,"id":"96c00f76","metadata":{},"outputs":[],"source":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":5}
