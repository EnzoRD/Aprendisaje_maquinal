{"cells":[{"cell_type":"markdown","id":"c158c679-8401-4f73-87a5-39fc2e1c8902","metadata":{"id":"c158c679-8401-4f73-87a5-39fc2e1c8902"},"source":["## M치quinas de soporte vectorial (SVM)"]},{"cell_type":"markdown","id":"991eec7f-e5de-400b-936b-b60c11ec3c40","metadata":{"id":"991eec7f-e5de-400b-936b-b60c11ec3c40"},"source":["Es un algoritmo de aprendizaje supervisado donde el objetivo es maximizar el margen definido por la distancia entre el hiperplano de separaci칩n y los puntos (de los datos de entrenamiento) m치s cercanas al hiperplano. Estos puntos son denominados _vectores soporte_.\n","\n","La idea que hay detr치s de las SVM de _margen m치ximo_ consiste en seleccionar el hiperplano separador que est치 a la misma distancia de los puntos m치s cercanos de cada clase.\n","<pre>\n","<center><img src=\"https://drive.google.com/uc?export=view&id=1crLg69QBCKqZdP5_G4gzAPRp_4dT7PPh\" width=800></center>\n","</pre>"]},{"cell_type":"markdown","id":"b819a697-1d55-49a6-a1d2-fafc5ae4faed","metadata":{"id":"b819a697-1d55-49a6-a1d2-fafc5ae4faed"},"source":["Las SVM tienen en su implementaci칩n una variable de holgura _C_ que permite que las restricciones no se cumplan de manera estricta. Esto es necesario en el caso de conjuntos que no son linealmente separables.\n","\n","<pre>\n","<center><img src=\"https://drive.google.com/uc?export=view&id=1csLqFA0B9eR5S7LAWJ9llpX3a3Kfa_a0\" width=800></center>\n","</pre>"]},{"cell_type":"markdown","id":"e6e6abb1-b99a-4f90-95d9-62ab203b76d7","metadata":{"id":"e6e6abb1-b99a-4f90-95d9-62ab203b76d7"},"source":["### 丘멆잺\n","Es un modelo muy sensible a la diferencia de escalas de los atributos, por lo que **es necesario esalar los datos**."]},{"cell_type":"markdown","id":"fdfc2246-eeac-4e57-9d23-22a7fcb29ab2","metadata":{"id":"fdfc2246-eeac-4e57-9d23-22a7fcb29ab2"},"source":["A continuaci칩n vamos a usar las SVM con algunos datasets guardados en la carpeta data: 'data1.mat', 'data2.mat' y 'data3.mat' 游늬"]},{"cell_type":"code","execution_count":1,"id":"ba355931-dc34-407c-9f7d-186f49c4ccff","metadata":{"id":"ba355931-dc34-407c-9f7d-186f49c4ccff"},"outputs":[],"source":["# importamos las librer칤as necesarias\n","import numpy as np\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","from matplotlib.colors import ListedColormap\n","from modules.funciones_auxiliares import plot_decision_regions"]},{"cell_type":"markdown","id":"fbccf152-5584-4980-b48c-7e9d304234d8","metadata":{"id":"fbccf152-5584-4980-b48c-7e9d304234d8"},"source":["### Dataset N췈 1"]},{"cell_type":"code","execution_count":2,"id":"7f0c4ffb-3aed-4f60-b29f-74bdf82ee24f","metadata":{"id":"7f0c4ffb-3aed-4f60-b29f-74bdf82ee24f"},"outputs":[{"data":{"text/plain":["(51,)"]},"execution_count":2,"metadata":{},"output_type":"execute_result"}],"source":["import scipy.io as sio\n","arch_mat = sio.loadmat('data/data1.mat')\n","\n","X = arch_mat['X']\n","y = arch_mat['y'].flatten()\n","y.shape"]},{"cell_type":"markdown","id":"5114b664-4940-4855-925f-1634815c3737","metadata":{"id":"5114b664-4940-4855-925f-1634815c3737"},"source":["Grafique los datos. Este dataset es linealmente separable. Notar que se tiene un outlier en una de las clases. Parte de este ejercicio es **probar con diferentes valores del par치metro C** y ver qu칠 efecto tiene la presencia del outlier en la regi칩n de separaci칩n."]},{"cell_type":"code","execution_count":null,"id":"ff24b242-aa7a-41d4-b141-c5bc3d20facb","metadata":{"id":"ff24b242-aa7a-41d4-b141-c5bc3d20facb"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"6538539f","metadata":{"id":"6538539f"},"source":["Realice los pasos necesarios para entrenar una SVM con kernel lineal. No es necesario para este ejercicio separar los datos en entrenamiento y prueba. Despu칠s grafique la regi칩n de decisi칩n usando la funci칩n `plot_decision_regions` de 'funciones_auxiliare.py'"]},{"cell_type":"code","execution_count":null,"id":"fc7fa6b6-213b-4909-9c13-e4f9ac121e7e","metadata":{"id":"fc7fa6b6-213b-4909-9c13-e4f9ac121e7e"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"36f779ce-bffb-4194-99ed-37320f4dd907","metadata":{"id":"36f779ce-bffb-4194-99ed-37320f4dd907"},"source":["### Dataset N췈 2\n","### SVM con kernel Gaussiano"]},{"cell_type":"markdown","id":"f0438b2d-931c-44d4-ad7b-c12cdff6c7c4","metadata":{"id":"f0438b2d-931c-44d4-ad7b-c12cdff6c7c4"},"source":["Uno de los _kernels_ m치s utilizado es el __radial basis function__ (RBF), que se conoce como __kernel Gaussiano__"]},{"cell_type":"markdown","id":"cc3a915b-6455-4c42-a37a-5f263a8dfbf5","metadata":{"id":"cc3a915b-6455-4c42-a37a-5f263a8dfbf5"},"source":["Como ver치 en la gr치fica, los datos no son linealmente separables. Con el kernel Gaussiano, el algoritmo del SVM podr치 encontrar la regi칩n de decisi칩n capaz de separar los datos correctamente y seguir los contornos del dataset."]},{"cell_type":"markdown","id":"49521b31-301f-4ba9-87be-feab6b9bbbd4","metadata":{"id":"49521b31-301f-4ba9-87be-feab6b9bbbd4"},"source":["La idea principal detr치s del uso de _kernels_ con datos que no son linealmente separables, es crear combinaciones no lineales de las caracter칤sticas originales y proyectarlas en un espacio de mayor dimensi칩n (mapeo mediante una funci칩n), donde los datos se vuelven linealmente separables.\n","\n","**Esta vez pruebe con distintos valores de `C` y `gamma`, c칩mo afectan los mismos en la regi칩n de decisi칩n?**"]},{"cell_type":"code","execution_count":null,"id":"5e1de1b7-567e-443e-beef-d6409246bc6c","metadata":{"id":"5e1de1b7-567e-443e-beef-d6409246bc6c"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"ce82537c-87f9-4f7e-a0df-815440d8dedd","metadata":{"id":"ce82537c-87f9-4f7e-a0df-815440d8dedd"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"53ec1c80-cb5f-4f10-834a-1af37c7fd156","metadata":{"id":"53ec1c80-cb5f-4f10-834a-1af37c7fd156","tags":[]},"outputs":[],"source":[]},{"cell_type":"markdown","id":"11e12cda-e195-4865-a147-cf2c366c4752","metadata":{"id":"11e12cda-e195-4865-a147-cf2c366c4752"},"source":["### Dataset N췈 3\n","El siguiente dataset _data3.mat_ posee datos para entrenamiento (_X_, _y_) y datos para validaci칩n (_X_val_, _y_val_)"]},{"cell_type":"code","execution_count":null,"id":"09a59a95-c15b-4f84-93ea-4d507559eaf1","metadata":{"id":"09a59a95-c15b-4f84-93ea-4d507559eaf1"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"5c987cb5-aee8-45fc-af46-01d1f6349082","metadata":{"id":"5c987cb5-aee8-45fc-af46-01d1f6349082"},"outputs":[],"source":[]},{"cell_type":"markdown","id":"06952f7b","metadata":{"id":"06952f7b"},"source":["Realice los pasos necesarios para entrenar una SVM con kernel gaussiano usando los datos de entrenamiento. Implemente in algoritmo para probar con distintos valores de `C` `[0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30]` y `gamma` `[0.01, 0.03, 0.1, 0.3, 1, 3, 10, 30]` y obtenga la combinaci칩n de par치metros (`C`, `gamma`) que produzca el mejor desempe침o del clasificador al evaluarla con los datos de validaci칩n. Puede utilizar el m칠todo `score()` del objeto.\n","\n","Despu칠s grafique la regi칩n de decisi칩n de la SVM con los par치metros obtenidos, usando la funci칩n `plot_decision_regions` de 'funciones_auxiliares.py'"]},{"cell_type":"code","execution_count":null,"id":"e5b9ab8a-042f-4227-9e71-df8722ff4689","metadata":{"id":"e5b9ab8a-042f-4227-9e71-df8722ff4689"},"outputs":[],"source":[]},{"cell_type":"code","execution_count":null,"id":"4153b80b-83f7-451b-8917-ae5f56864b71","metadata":{"id":"4153b80b-83f7-451b-8917-ae5f56864b71"},"outputs":[],"source":[]}],"metadata":{"colab":{"provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.4"}},"nbformat":4,"nbformat_minor":5}
